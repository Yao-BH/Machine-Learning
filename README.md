# 【从理论到实践】一个项目带你走进机器学习，走入数据分析
&emsp;&emsp;刚刚开始学习，你是否对机器学习充满疑惑？怎样进行数据分析、数据建模。

接下来我将通过泰坦尼克号生存预测这一个典型案例加深你对机器学习的理解，同时亲身体会数据分析的流程。

>从理论到实践，由浅入深，带你一步步了解它的魅力

>该方案通过各种经典模型让你从零基础开始，了解当下比较流行的建模方法

<img style="display: block; margin: 0 auto;" src="https://ai-studio-static-online.cdn.bcebos.com/4090a709f2c24252b605a787770fef0aed9180d343da4a99bf96c71826c3c0c0" width = "300%" height = "300%" />

# 一、数据分析的流程（理论）
## 1.问题定义
&emsp;&emsp;做任何事情都有一个目标，数据分析也不例外。如果目的明确，所有问题都可以迎刃而解。所以在开展数据分析之前，要想清楚：为什么要开展数据分析？通过这次数据分析我要解决什么问题？只有明确数据分析的目标，数据分析才不会偏离方向，否则得出的数据分析结果不仅仅没有指导意义，甚至可能将决策者引入歧途，后果严重。

&emsp;&emsp;比较典型的场景是我们需要针对企业的数据进行分析，比如公司通常会有销售数据、用户数据、运营数据、产品生产数据……你需要从这些数据里获得哪些有用的信息，对策略的制定进行指导呢？又比如你需要做的是一份市场调研或者行业分析，那么你需要知道你需要获得关于这个行业的哪些信息。

**首先你需要确定去分析的问题是什么？你想得出哪些结论？**

&emsp;&emsp;比如某地区空气质量变化的趋势是什么？

&emsp;&emsp;如何基于历史数据预测未来某个阶段用户行为？

&emsp;&emsp;当明确分析目的明确后，我们就要梳理分析思路，并搭建分析框架，把分析目的分解成若干个不同的分析要点，即如何具体展开数据分析，需要从那几个角度进行分析，采用哪些分析指标。

&emsp;&emsp;只有明确了分析目的，分析框架才能跟着确定下来，最后还要确保分析框架的体系化，使分析结果具有说服力。那数据分析体系化该如何理解？

&emsp;&emsp;体系化也就是逻辑化，简单来说就是先分析什么，后分析什么，使得各个分析点之间具有逻辑联系。这也是很多人常常感到困扰的问题，比如经常不知从哪个方面入手，分析的内容和指标常常被质疑是否合理，完整，而自己也说不出个所以然来，所以，体系化就是为了让你的分析框架具有说服力。

## 2.数据获取
&emsp;&emsp;有了具体的问题，你就需要获取相关的数据了。比如你要探究空气质量变化的趋势，你可能就需要收集北京最近几年的空气质量数据、天气数据，甚至工厂数据、气体排放数据、重要日程数据等等。如果你要分析影响公司销售的关键因素，你就需要调用公司的历史销售数据、用户画像数据、广告投放数据等。

**数据的获取方式有多种**

* 第一种一是公司的销售、用户数据，可以直接从企业数据库调取，所以你需要SQL技能去完成数据提取等的数据库管理工作。比如你可以根据你的需要提取2021年所有的销售数据、提取今年销量最大的100件商品的数据、提取上海、广东地区用户的消费数据……，SQL可以通过简单的命令帮你完成这些工作。

* 第二种是获取外部的公开数据集，一些科研机构、企业、政府会开放一些数据，你需要到特定的网站去下载这些数据。这些数据集通常比较完善、质量相对较高。当然这种方式也有一些缺陷，通常数据会发布的比较滞后，但通常因为客观性、权威性，仍然具有很大的价值。（不过在我们个人学习阶段都会采用公开数据集的方法，比如本项目就采用paddle的公开数据集）

* 第三种是编写网页爬虫，去收集互联网上的数据。比如你可以通过爬虫获取招聘网站某一职位的招聘信息，爬取租房网站上某城市的租房信息，爬取豆瓣评分评分最高的电影列表，获取知乎点赞排行、网易云音乐评论排行列表。基于互联网爬取的数据，你可以对某个行业、某种人群进行分析，这算是非常靠谱的市场调研、竞品分析的方式了。

&emsp;&emsp;当然，比较BUG的一点是，你通常并不能够获得所有你需要的数据，这对你的分析结果是有一定影响的，但不不影响的是，你通过有限的可获取的数据，提取更多有用的信息。

## 3.数据预处理
**&emsp;&emsp;数据预处理是从数据中检测，纠正或删除损坏，不准确或不适用于模型的记录的过程**
* 可能面对的问题有：<br>数据类型不同，比如有的是文字，有的是数字，有的含时间序列，有的连续，有的间断。也可能，数据的质量不行，有噪声，有异常，有缺失，数据出错，量纲不一，有重复，数据是偏态，数据量太大或太小
* 数据预处理的目的：<br>让数据适应模型，匹配模型的需求

**&emsp;&emsp;现实世界中数据大体上都是不完整，不一致的脏数据，无法直接进行数据分析，或分析结果差强人意。
数据预处理有多种方法：数据清理，数据集成，数据变换，数据归约等。把这些影响分析的数据处理好，才能获得更加精确地分析结果。**
![](https://ai-studio-static-online.cdn.bcebos.com/b4eb70851ceb4615994621c93431609d1651a7cabd8b4b78a3b775566750e0d1)
## 4.数据分析与数据建模
&emsp;&emsp;在这个部分需要了解基本的数据分析方法、数据挖掘算法，了解不同方法适用的场景和适合的问题。分析时应切忌滥用和误用统计分析方法。滥用和误用统计分析方法主要是由于对方法能解决哪类问题、方法适用的前提、方法对数据的要求不清等原因造成的。

&emsp;&emsp;另外，选择几种统计分析方法对数据进行探索性的反复分析也是极为重要的。每一种统计分析方法都有自己的特点和局限，因此，一般需要选择几种方法反复印证分析，仅依据一种分析方法的结果就断然下结论是不科学的。

&emsp;&emsp;比如你发现在一定条件下，销量和价格是正比关系，那么你可以据此建立一个线性回归模型，你发现价格和广告是非线性关系，你可以先建立一个逻辑回归模型来进行分析。

&emsp;&emsp;一般情况下，回归分析的方法可以满足很大一部分的分析需求，当然你也可以了解一些数据挖掘的算法、特征提取的方法来优化自己的模型，获得更好地结果。
